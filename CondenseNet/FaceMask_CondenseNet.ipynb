{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "import torch.nn.functional as F\n",
    "from torch import cuda\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "import timm \n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch.nn.modules.utils import _ntuple\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/storage_labs/3030/BelyakovM/FaceMask_presence/ds'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedGroupConv(nn.Module):\n",
    "    global_progress = 0.0\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, \n",
    "                 condense_factor=None, dropout_rate=0.):\n",
    "        super(LearnedGroupConv, self).__init__()\n",
    "        self.norm = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        if self.dropout_rate > 0:\n",
    "            self.drop = nn.Dropout(dropout_rate, inplace=False)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride,\n",
    "                              padding, dilation, groups=1, bias=False)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.groups = groups\n",
    "        self.condense_factor = condense_factor\n",
    "        if self.condense_factor is None:\n",
    "            self.condense_factor = self.groups\n",
    "        ### Parameters that should be carefully used\n",
    "        self.register_buffer('_count', torch.zeros(1))\n",
    "        self.register_buffer('_stage', torch.zeros(1))\n",
    "        self.register_buffer('_mask', torch.ones(self.conv.weight.size()))\n",
    "        ### Check if arguments are valid\n",
    "        assert self.in_channels % self.groups == 0, \"group number can not be divided by input channels\"\n",
    "        assert self.in_channels % self.condense_factor == 0, \"condensation factor can not be divided by input channels\"\n",
    "        assert self.out_channels % self.groups == 0, \"group number can not be divided by output channels\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._check_drop()\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        if self.dropout_rate > 0:\n",
    "            x = self.drop(x)\n",
    "        ### Masked output\n",
    "        weight = self.conv.weight * self.mask\n",
    "        return F.conv2d(x, weight, None, self.conv.stride,\n",
    "                        self.conv.padding, self.conv.dilation, 1)\n",
    "\n",
    "    def _check_drop(self):\n",
    "        progress = LearnedGroupConv.global_progress\n",
    "        delta = 0\n",
    "        ### Get current stage\n",
    "        for i in range(self.condense_factor - 1):\n",
    "            if progress * 2 < (i + 1) / (self.condense_factor - 1):\n",
    "                stage = i\n",
    "                break\n",
    "        else:\n",
    "            stage = self.condense_factor - 1\n",
    "        ### Check for dropping\n",
    "        if not self._reach_stage(stage):\n",
    "            self.stage = stage\n",
    "            delta = self.in_channels // self.condense_factor\n",
    "        if delta > 0:\n",
    "            self._dropping(delta)\n",
    "        return\n",
    "\n",
    "    def _dropping(self, delta):\n",
    "        weight = self.conv.weight * self.mask\n",
    "        ### Sum up all kernels\n",
    "        ### Assume only apply to 1x1 conv to speed up\n",
    "        assert weight.size()[-1] == 1\n",
    "        weight = weight.abs().squeeze()\n",
    "        assert weight.size()[0] == self.out_channels\n",
    "        assert weight.size()[1] == self.in_channels\n",
    "        d_out = self.out_channels // self.groups\n",
    "        ### Shuffle weight\n",
    "        weight = weight.view(d_out, self.groups, self.in_channels)\n",
    "        weight = weight.transpose(0, 1).contiguous()\n",
    "        weight = weight.view(self.out_channels, self.in_channels)\n",
    "        ### Sort and drop\n",
    "        for i in range(self.groups):\n",
    "            wi = weight[i * d_out:(i + 1) * d_out, :]\n",
    "            ### Take corresponding delta index\n",
    "            di = wi.sum(0).sort()[1][self.count:self.count + delta]\n",
    "            for d in di.data:\n",
    "                self._mask[i::self.groups, d, :, :].fill_(0)\n",
    "        self.count = self.count + delta\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        return int(self._count[0])\n",
    "\n",
    "    @count.setter\n",
    "    def count(self, val):\n",
    "        self._count.fill_(val)\n",
    "\n",
    "    @property\n",
    "    def stage(self):\n",
    "        return int(self._stage[0])\n",
    "        \n",
    "    @stage.setter\n",
    "    def stage(self, val):\n",
    "        self._stage.fill_(val)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return Variable(self._mask)\n",
    "\n",
    "    def _reach_stage(self, stage):\n",
    "        return (self._stage >= stage).all()\n",
    "\n",
    "    @property\n",
    "    def lasso_loss(self):\n",
    "        if self._reach_stage(self.groups - 1):\n",
    "            return 0\n",
    "        weight = self.conv.weight * self.mask\n",
    "        ### Assume only apply to 1x1 conv to speed up\n",
    "        assert weight.size()[-1] == 1\n",
    "        weight = weight.squeeze().pow(2)\n",
    "        d_out = self.out_channels // self.groups\n",
    "        ### Shuffle weight\n",
    "        weight = weight.view(d_out, self.groups, self.in_channels)\n",
    "        weight = weight.sum(0).clamp(min=1e-6).sqrt()\n",
    "        return weight.sum()\n",
    "\n",
    "\n",
    "def ShuffleLayer(x, groups):\n",
    "    batchsize, num_channels, height, width = x.data.size()\n",
    "    channels_per_group = num_channels // groups\n",
    "    ### reshape\n",
    "    x = x.view(batchsize, groups,\n",
    "               channels_per_group, height, width)\n",
    "    ### transpose\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "    ### flatten\n",
    "    x = x.view(batchsize, -1, height, width)\n",
    "    return x\n",
    "\n",
    "\n",
    "class CondensingLinear(nn.Module):\n",
    "    def __init__(self, model, drop_rate=0.5):\n",
    "        super(CondensingLinear, self).__init__()\n",
    "        self.in_features = int(model.in_features*drop_rate)\n",
    "        self.out_features = model.out_features\n",
    "        self.linear = nn.Linear(self.in_features, self.out_features)\n",
    "        self.register_buffer('index', torch.LongTensor(self.in_features))\n",
    "        _, index = model.weight.data.abs().sum(0).sort()\n",
    "        index = index[model.in_features-self.in_features:]\n",
    "        self.linear.bias.data = model.bias.data.clone()\n",
    "        for i in range(self.in_features):\n",
    "            self.index[i] = index[i]\n",
    "            self.linear.weight.data[:, i] = model.weight.data[:, index[i]]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.index_select(x, 1, Variable(self.index))\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CondensingConv(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CondensingConv, self).__init__()\n",
    "        self.in_channels = model.conv.in_channels \\\n",
    "                         * model.groups // model.condense_factor\n",
    "        self.out_channels = model.conv.out_channels\n",
    "        self.groups = model.groups\n",
    "        self.condense_factor = model.condense_factor\n",
    "        self.norm = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "                              kernel_size=model.conv.kernel_size,\n",
    "                              padding=model.conv.padding,\n",
    "                              groups=self.groups,\n",
    "                              bias=False,\n",
    "                              stride=model.conv.stride)\n",
    "        self.register_buffer('index', torch.LongTensor(self.in_channels))\n",
    "        index = 0\n",
    "        mask = model._mask.mean(-1).mean(-1)\n",
    "        for i in range(self.groups):\n",
    "            for j in range(model.conv.in_channels):\n",
    "                if index < (self.in_channels // self.groups) * (i + 1) \\\n",
    "                         and mask[i, j] == 1:\n",
    "                    for k in range(self.out_channels // self.groups):\n",
    "                        idx_i = int(k + i * (self.out_channels // self.groups))\n",
    "                        idx_j = index % (self.in_channels // self.groups)\n",
    "                        self.conv.weight.data[idx_i, idx_j, :, :] = \\\n",
    "                            model.conv.weight.data[int(i + k * self.groups), j, :, :]\n",
    "                        self.norm.weight.data[index] = model.norm.weight.data[j]\n",
    "                        self.norm.bias.data[index] = model.norm.bias.data[j]\n",
    "                        self.norm.running_mean[index] = model.norm.running_mean[j]\n",
    "                        self.norm.running_var[index] = model.norm.running_var[j]\n",
    "                    self.index[index] = j\n",
    "                    index += 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.index_select(x, 1, Variable(self.index))\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = ShuffleLayer(x, self.groups)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CondenseLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, drop_rate=0.5):\n",
    "        super(CondenseLinear, self).__init__()\n",
    "        self.in_features = int(in_features*drop_rate)\n",
    "        self.out_features = out_features\n",
    "        self.linear = nn.Linear(self.in_features, self.out_features)\n",
    "        self.register_buffer('index', torch.LongTensor(self.in_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.index_select(x, 1, Variable(self.index))\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CondenseConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 stride=1, padding=0, groups=1):\n",
    "        super(CondenseConv, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.groups = groups\n",
    "        self.norm = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(self.in_channels, self.out_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              stride=stride,\n",
    "                              padding=padding,\n",
    "                              groups=self.groups,\n",
    "                              bias=False)\n",
    "        self.register_buffer('index', torch.LongTensor(self.in_channels))\n",
    "        self.index.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.index_select(x, 1, Variable(self.index))\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = ShuffleLayer(x, self.groups)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 stride=1, padding=0, groups=1):\n",
    "        super(Conv, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(in_channels))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=kernel_size,\n",
    "                                          stride=stride,\n",
    "                                          padding=padding, bias=False,\n",
    "                                          groups=groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='PyTorch Condensed Convolutional Networks')\n",
    "\n",
    "parser.add_argument('--data', metavar='DIR',help='path to dataset')\n",
    "\n",
    "parser.add_argument('--model', default='condensenet', type=str, metavar='M',\n",
    "                    help='model to train the dataset')\n",
    "parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=120, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 256)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate (default: 0.1)')\n",
    "parser.add_argument('--lr-type', default='cosine', type=str, metavar='T',\n",
    "                    help='learning rate strategy (default: cosine)',\n",
    "                    choices=['cosine', 'multistep'])\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum (default: 0.9)')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                    help='use pre-trained model (default: false)')\n",
    "parser.add_argument('--no-save-model', dest='no_save_model', action='store_true',\n",
    "                    help='only save best model (default: false)')\n",
    "parser.add_argument('--manual-seed', default=0, type=int, metavar='N',\n",
    "                    help='manual seed (default: 0)')\n",
    "parser.add_argument('--gpu', default='cuda:0',\n",
    "                    help='cuda:0')\n",
    "\n",
    "parser.add_argument('--savedir', type=str, metavar='PATH', default='results/savedir',\n",
    "                    help='path to save result and checkpoint (default: results/savedir)')\n",
    "parser.add_argument('--resume', action='store_true',\n",
    "                    help='use latest checkpoint if have any (default: none)')\n",
    "\n",
    "parser.add_argument('--stages', type=str, metavar='STAGE DEPTH',\n",
    "                    help='per layer depth')\n",
    "parser.add_argument('--bottleneck', default=4, type=int, metavar='B',\n",
    "                    help='bottleneck (default: 4)')\n",
    "parser.add_argument('--group-1x1', type=int, metavar='G', default=4,\n",
    "                    help='1x1 group convolution (default: 4)')\n",
    "parser.add_argument('--group-3x3', type=int, metavar='G', default=4,\n",
    "                    help='3x3 group convolution (default: 4)')\n",
    "parser.add_argument('--condense-factor', type=int, metavar='C', default=4,\n",
    "                    help='condense factor (default: 4)')\n",
    "parser.add_argument('--growth', type=str, metavar='GROWTH RATE',\n",
    "                    help='per layer growth')\n",
    "parser.add_argument('--reduction', default=0.5, type=float, metavar='R',\n",
    "                    help='transition reduction (default: 0.5)')\n",
    "parser.add_argument('--dropout-rate', default=0, type=float,\n",
    "                    help='drop out (default: 0)')\n",
    "parser.add_argument('--group-lasso-lambda', default=0., type=float, metavar='LASSO',\n",
    "                    help='group lasso loss weight (default: 0)')\n",
    "\n",
    "parser.add_argument('--evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set (default: false)')\n",
    "parser.add_argument('--convert-from', default=None, type=str, metavar='PATH',\n",
    "                    help='path to saved checkpoint (default: none)')\n",
    "parser.add_argument('--evaluate-from', default=None, type=str, metavar='PATH',\n",
    "                    help='path to saved checkpoint (default: none)')\n",
    "args = parser.parse_args([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.stages = '4-6-8-10-8'\n",
    "args.growth = '8-16-32-64-128'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "args.stages = list(map(int, args.stages.split('-')))\n",
    "args.growth = list(map(int, args.growth.split('-')))\n",
    "args.num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "__all__ = ['CondenseNet']\n",
    "\n",
    "\n",
    "class _DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, args):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.group_1x1 = args.group_1x1\n",
    "        self.group_3x3 = args.group_3x3\n",
    "        ### 1x1 conv i --> b*k\n",
    "        self.conv_1 = LearnedGroupConv(in_channels, args.bottleneck * growth_rate,\n",
    "                                       kernel_size=1, groups=self.group_1x1,\n",
    "                                       condense_factor=args.condense_factor,\n",
    "                                       dropout_rate=args.dropout_rate)\n",
    "        ### 3x3 conv b*k --> k\n",
    "        self.conv_2 = Conv(args.bottleneck * growth_rate, growth_rate,\n",
    "                           kernel_size=3, padding=1, groups=self.group_3x3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_ = x\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        return torch.cat([x_, x], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, in_channels, growth_rate, args):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(in_channels + i * growth_rate, growth_rate, args)\n",
    "            self.add_module('denselayer_%d' % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Module):\n",
    "    def __init__(self, in_channels, args):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CondenseNet(nn.Module):\n",
    "    def __init__(self, args):\n",
    "\n",
    "        super(CondenseNet, self).__init__()\n",
    "\n",
    "        self.stages = args.stages\n",
    "        self.growth = args.growth\n",
    "        assert len(self.stages) == len(self.growth)\n",
    "        self.args = args\n",
    "        self.progress = 0.0\n",
    "        if args.data in ['cifar10', 'cifar100']:\n",
    "            self.init_stride = 1\n",
    "            self.pool_size = 8\n",
    "        else:\n",
    "            self.init_stride = 2\n",
    "            self.pool_size = 7\n",
    "\n",
    "        self.features = nn.Sequential()\n",
    "        ### Initial nChannels should be 3\n",
    "        self.num_features = 2 * self.growth[0]\n",
    "        ### Dense-block 1 (224x224)\n",
    "        self.features.add_module('init_conv', nn.Conv2d(3, self.num_features,\n",
    "                                                        kernel_size=3,\n",
    "                                                        stride=self.init_stride,\n",
    "                                                        padding=1,\n",
    "                                                        bias=False))\n",
    "        for i in range(len(self.stages)):\n",
    "            ### Dense-block i\n",
    "            self.add_block(i)\n",
    "        ### Linear layer\n",
    "        self.classifier = nn.Linear(self.num_features, args.num_classes)\n",
    "\n",
    "        ### initialize\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "        return\n",
    "\n",
    "    def add_block(self, i):\n",
    "        ### Check if ith is the last one\n",
    "        last = (i == len(self.stages) - 1)\n",
    "        block = _DenseBlock(\n",
    "            num_layers=self.stages[i],\n",
    "            in_channels=self.num_features,\n",
    "            growth_rate=self.growth[i],\n",
    "            args=self.args,\n",
    "        )\n",
    "        self.features.add_module('denseblock_%d' % (i + 1), block)\n",
    "        self.num_features += self.stages[i] * self.growth[i]\n",
    "        if not last:\n",
    "            trans = _Transition(in_channels=self.num_features,\n",
    "                                args=self.args)\n",
    "            self.features.add_module('transition_%d' % (i + 1), trans)\n",
    "        else:\n",
    "            self.features.add_module('norm_last',\n",
    "                                     nn.BatchNorm2d(self.num_features))\n",
    "            self.features.add_module('relu_last',\n",
    "                                     nn.ReLU(inplace=True))\n",
    "            self.features.add_module('pool_last',\n",
    "                                     nn.AvgPool2d(self.pool_size))\n",
    "\n",
    "    def forward(self, x, progress=None):\n",
    "        if progress:\n",
    "            LearnedGroupConv.global_progress = progress\n",
    "        features = self.features(x)\n",
    "        out = features.view(features.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = CondenseNet(args)\n",
    "\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "#model_ft = nn.DataParallel(model_ft)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.1862 Acc: 0.9200\n",
      "val Loss: 0.1197 Acc: 0.9588\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.1746 Acc: 0.9258\n",
      "val Loss: 0.1128 Acc: 0.9597\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1561 Acc: 0.9346\n",
      "val Loss: 0.1065 Acc: 0.9647\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1546 Acc: 0.9358\n",
      "val Loss: 0.1014 Acc: 0.9660\n",
      "\n",
      "Training complete in 21m 48s\n",
      "Best val Acc: 0.966049\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dima(name_model,model, size_1, size_2, name_device='cpu'):\n",
    "    '''\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    device = torch.device(name_device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dummy_input = torch.randn(1, 3, size_1, size_2, dtype=torch.float).to(device)\n",
    "    # INIT LOGGERS\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    repetitions = 1000\n",
    "    timings = np.zeros((repetitions,1))\n",
    "\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _= model(dummy_input)\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "    # MEASURE PERFORMANCE\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            dummy_input = torch.randn(1, 3, size_1, size_2).type(torch.cuda.FloatTensor).to(device)\n",
    "            starter.record()\n",
    "            _ = model(dummy_input)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    print(name_model, mean_syn, f' {size_1}_{size_2}')\n",
    "    return mean_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CondenseNet 20.61715446090698  224_224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.61715446090698"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time_dima('CondenseNet',model_ft,224,224,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:51: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
     ]
    }
   ],
   "source": [
    "dummy = torch.randn(1, 3, 224, 224, device='cuda')\n",
    "input_names = [ \"actual_input_1\" ] \n",
    "output_names = [ \"output1\" ]\n",
    "#model_ft.set_swish(memory_efficient=False)\n",
    "torch.onnx.export(model_ft, dummy, \"FaceMask_CondenseNet_224.onnx\", verbose=False, input_names=input_names, output_names=output_names,export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 24 08:13:43 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.44       Driver Version: 440.44       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 31%   20C    P8     1W / 250W |  10978MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 29%   21C    P8     5W / 250W |   1264MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
